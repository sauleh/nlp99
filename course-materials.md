---
layout: page
title: Course Materials
permalink: /course-materials/
---

{% include image.html url="/_images/nlpbook.jpg" width=175 align="right" %}

## Books
* Manning, Christopher D., Christopher D. Manning, and Hinrich Sch√ºtze. Foundations of statistical natural language processing. MIT press, 1999. [PDF](https://www.cs.vassar.edu/~cs366/docs/Manning_Schuetze_StatisticalNLP.pdf), [Companion Website](https://nlp.stanford.edu/fsnlp/).

* Jurafsky, Dan, and James H. Martin. Speech and language processing. Vol. 3. London: Pearson, 2014 [PDF](https://web.stanford.edu/~jurafsky/slp3/ed3book.pdf), [Page](https://web.stanford.edu/~jurafsky/slp3/).

* Koehn, Philipp. Statistical machine translation. Cambridge University Press, 2009. [Page](http://www.statmt.org/book/)
## Online Courses
This course closely follows Prof. Manning's [NLP with deep learning](http://web.stanford.edu/class/cs224n/) course. There is an earlier version of the course with a more traditional approach by Dan Jurafsky and Christopher Manning on Natural Language Processing which is also highly recommended. You can find the slides of the earlier version of the course [here](https://web.stanford.edu/~jurafsky/NLPCourseraSlides.html) and the videos [here](https://www.youtube.com/playlist?list=PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ&disable_polymer=true). Other online courses:
* From Languge to Information by Dan Jurafsky: [videos](https://www.youtube.com/channel/UC_48v322owNVtORXuMeRmpA), course [page](http://web.stanford.edu/class/cs124/).
* Food Talks: The Language of Food by Dan Jurafsky ([Course Page](http://web.stanford.edu/class/think53/))

Prof. Dan Jurafsky is a leading reasearcher and teacher in Natural Language Processing. You can find a list of courses taught by him [here](https://web.stanford.edu/~jurafsky/teaching.html).


## NLP at Other Universities
* Chris Mannings's [Natural Language Processing with Deep Learning](http://web.stanford.edu/class/cs224n/) course at Stanford.
* Deep Learning for NLP at [Oxford](https://www.cs.ox.ac.uk/teaching/courses/2016-2017/dl/).
* Advanced NLP at [MIT](Advanced Natural Language Processing).
* Introduction to Machine Learning at [MIT](https://stellar.mit.edu/S/course/6/sp16/6.036/index.html).
* NLP related courses at [MIT](http://nlp.csail.mit.edu/teaching)
* Michael Collins [NLP Course](http://www.cs.columbia.edu/~mcollins/cs4705-spring2019/) at Columbia.
* Dan Klein's [NLP Course](https://people.eecs.berkeley.edu/~klein/cs288/sp10/) at Berkeley.
* [NLP](http://people.ischool.berkeley.edu/~dbamman/nlp18.html) and Applied NLP at [Berekley](http://people.ischool.berkeley.edu/~dbamman/info256.html).
* NLP at [UIUC](https://courses.engr.illinois.edu/cs546/sp2018/).
* NLP at [Maryland](http://www.cs.umd.edu/class/fall2018/cmsc470/), also [here](http://users.umiacs.umd.edu/~jbg/teaching/CMSC_470/).

## Tutorials
* Deep Learning for Natural Language Processing: Tutorials with Jupyter Notebooks ([link](https://insights.untapt.com/deep-learning-for-natural-language-processing-tutorials-with-jupyter-notebooks-ad67f336ce3f)).
* How to solve 90% of NLP problems: a step-by-step guide ([link](https://blog.insightdatascience.com/how-to-solve-90-of-nlp-problems-a-step-by-step-guide-fda605278e4e))
* The Advantures in Machine Learning blog ([link](http://adventuresinmachinelearning.com/))
* ACL 2012 + NAACL 2013 Tutorial: Deep Learning for NLP (without Magic) ([link](https://www.socher.org/index.php/DeepLearningTutorial/DeepLearningTutorial), [slides](http://lxmls.it.pt/2014/socher-lxmls.pdf))
* 

## More Reading Material
* [The Language of Food](https://web.stanford.edu/~jurafsky/thelanguageoffood.html)
* Bird, Steven, Ewan Klein, and Edward Loper. Natural language processing with Python: analyzing text with the natural language toolkit. " O'Reilly Media, Inc.", 2009.([link](https://www.nltk.org/book/))
* [The foundation of data science](http://data8.org/).

## Resources
* [NLP for Hackers](https://nlpforhackers.io/)
* [Using Google-Colab like a PRO](https://medium.com/@robertbracco1/configuring-google-colab-like-a-pro-d61c253f7573)
* [Colab setup for Conda, SSH and GitHub](https://colab.research.google.com/drive/1fxqM06gZ9Mt3wucIN9M1svLHokZusmVC)
* [CNN Explainer](https://poloclub.github.io/cnn-explainer/#article-input)
* [BiDAF Notebook](https://colab.research.google.com/github/kushalj001/pytorch-question-answering/blob/master/2.%20BiDAF.ipynb#scrollTo=HM_ygDbWSDXV)
* [Seq-Seq NMT Visualization](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)
* [Transformer Illustrated](http://jalammar.github.io/illustrated-transformer/)
* [BERT Illustrated](http://jalammar.github.io/illustrated-bert/)
* [GPT-2 Illustrated](http://jalammar.github.io/illustrated-gpt2/)
* [Neural Attention Visualization](https://distill.pub/2016/augmented-rnns/)
* [FAST-AI Book and Course](https://docs.fast.ai/)
## NLP Projects
* QANTA.org

## Answers
* What is a 1 by 1 convolution for? [link](https://machinelearningmastery.com/introduction-to-1x1-convolutions-to-reduce-the-complexity-of-convolutional-neural-networks/)
* 
